{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uqu2_x95y8jd"
   },
   "source": [
    "The objective of this task is to predict keypoint positions on face images. This can be used as a building block in several applications, such as:\n",
    "\n",
    "tracking faces in images and video\n",
    "analysing facial expressions\n",
    "detecting dysmorphic facial signs for medical diagnosis\n",
    "biometrics / face recognition\n",
    "Detecing facial keypoints is a very challenging problem.  Facial features vary greatly from one individual to another, and even for a single individual, there is a large amount of variation due to 3D pose, size, position, viewing angle, and illumination conditions. Computer vision research has come a long way in addressing these difficulties, but there remain many opportunities for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pvO6UYmSs-QE"
   },
   "outputs": [],
   "source": [
    "#Mounting the Google Drive for accessing the dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gRNL_3_P1sjF"
   },
   "outputs": [],
   "source": [
    "#Import the packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from skimage import data, io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, Convolution2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, Conv2D,MaxPool2D, ZeroPadding2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QgVU5Z6o1vcN"
   },
   "outputs": [],
   "source": [
    "#Getting the dataset and storing into one dataframe\n",
    "df_training = pd.read_csv(\"/content/gdrive/My Drive/facial-keypoints-detection/training.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62CZNHyd2z2Z"
   },
   "outputs": [],
   "source": [
    "#Filling the null or NA data in Dataframe\n",
    "df_training.fillna(method=\"ffill\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PNN3DqNcGy3"
   },
   "outputs": [],
   "source": [
    "#Dividing the data into Source and target variables\n",
    "X = df_training.Image\n",
    "y = df_training.drop('Image', axis = 1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4HsonegNcknS"
   },
   "outputs": [],
   "source": [
    "#Write a function to Normalize the data of better training\n",
    "def convertImage(Imagedata):\n",
    "  newData = [np.array(i.split(' ')).astype(np.float32) for i in Imagedata]\n",
    "  newData = np.array(newData).reshape(Imagedata.shape[0], 96, 96, 1)\n",
    "  newData /= 255\n",
    "  return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ktmM0mfrfsSV"
   },
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "X = convertImage(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ob6BYkv0xMQ9"
   },
   "outputs": [],
   "source": [
    "#Visualizing the image with Image features\n",
    "plt.imshow(X[0].reshape(96,96),cmap='gray')\n",
    "t = y.iloc[0]\n",
    "plt.scatter(t[0::2], t[1::2], c='red', marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wp-ucAtgvrf5"
   },
   "outputs": [],
   "source": [
    "#Function to define a model\n",
    "def create_model():\n",
    "  model = Sequential()\n",
    "  model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape=(96,96,1)))\n",
    "\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Convolution2D(96, (3,3), padding='same', use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
    "  # model.add(BatchNormalization())\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Convolution2D(128, (3,3),padding='same', use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Convolution2D(256, (3,3),padding='same',use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "  model.add(Convolution2D(512, (3,3), padding='same', use_bias=False))\n",
    "  model.add(LeakyReLU(alpha = 0.1))\n",
    "  model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(512,activation='relu'))\n",
    "  model.add(Dropout(0.1))\n",
    "  model.add(Dense(30))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTA79v2Pucje"
   },
   "outputs": [],
   "source": [
    "#Accessing TPU on colab\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "\n",
    "try:\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "except ValueError:\n",
    "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKkST-iQvE9J"
   },
   "outputs": [],
   "source": [
    "#Create model with TPU\n",
    "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
    "  model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbCm6gbWhJAe"
   },
   "outputs": [],
   "source": [
    "#Compiling the model with Adam optimizer, loss with MSE and accuracy for matrics\n",
    "model.compile(loss='mean_squared_error',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vk3ZsKPwhQyg"
   },
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "model.fit(X, y, batch_size=256, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMTs7rhZzEQc"
   },
   "outputs": [],
   "source": [
    "#Accessing the data for testing\n",
    "df_testing = pd.read_csv(\"/content/gdrive/My Drive/facial-keypoints-detection/test.csv\")\n",
    "df_testing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SgLpUzGzJLf"
   },
   "outputs": [],
   "source": [
    "#Normalize the testing data\n",
    "test_image = convertImage(df_testing.Image)\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A06TEomY0JQt"
   },
   "outputs": [],
   "source": [
    "#Predicting based on test data\n",
    "test_predict = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cQq1TVCf0kCw"
   },
   "outputs": [],
   "source": [
    "test_predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuX9oxBT2kgx"
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_image[0].reshape(96,96),cmap='gray')\n",
    "t = test_predict[0]\n",
    "plt.scatter(t[0: :2], t[1: :2], c='red', marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CoCba6XxRZwG"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[0].reshape(96,96),cmap='gray')\n",
    "t = y.iloc[0]\n",
    "plt.scatter(t[0::2], t[1::2], c='red', marker='x')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "FaceFeatureDetection.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
